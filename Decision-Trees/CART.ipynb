{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Node(object):\n",
    "    def __init__(self, name=None, value=None, delta=None, gini_after=None):\n",
    "        self.feature_name = name\n",
    "        self.feature_value = value\n",
    "        self.delta = delta\n",
    "        self.gini_after = gini_after\n",
    "        self.left = None\n",
    "        self.right = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DecisionTree(object):\n",
    "    def __init__(self, depth=2, score='gini'):\n",
    "        \"\"\"\n",
    "        param depth: speicifies depth of the three. Root node is depth 0\n",
    "        param score: speicifes score to use for split\n",
    "        \"\"\"\n",
    "        self._depth = depth\n",
    "        self._score = score\n",
    "        self._current_depth = -1\n",
    "        self._tree = []\n",
    "    def fit(self, X_train, y_train):\n",
    "        \"\"\"\n",
    "        recursively builds the tree. At each level, \n",
    "        it finds the best node, \n",
    "        which is calculated by examining all the unique\n",
    "        values of all the features\n",
    "        and calculates delta value. \n",
    "        the feature-value pair with highest delta \n",
    "        value is chosen for split.\n",
    "        Delta value is calculated by subtracting \n",
    "        the Gini index of data the \n",
    "        function has received, from \n",
    "        the Gini index after for a\n",
    "        every feature-value pair. \n",
    "        \"\"\"\n",
    "        X_train.index = range(len(X_train.index))\n",
    "        y_train.index = range(len(y_train.index))\n",
    "        if self._current_depth == self._depth:\n",
    "            node = Node(name='leaf', value=y_train)\n",
    "            self._tree.append(node)\n",
    "            print('class distribution: ', y_train)\n",
    "            return node\n",
    "        self._current_depth += 1\n",
    "        print('cur_depth: ', self._current_depth)\n",
    "        features = X_train.columns.values\n",
    "        node = self._best_node(X_train, y_train)\n",
    "        if not node:\n",
    "            node = Node(name='leaf', value=y_train)\n",
    "            self._tree.append(node)\n",
    "            print('this is a pure leaf')\n",
    "            print('class distribution: ', y_train)\n",
    "            self._current_depth -= 1\n",
    "            return node\n",
    "        print('feature_name: ', node.feature_name,\n",
    "              'feature_split: ', node.feature_value,\n",
    "              'delta: ', node.delta, \n",
    "             'gini: ', node.gini_after)\n",
    "        left_subset_X, left_subset_y, right_subset_X, right_subset_y = self._subset(node, X_train, y_train)\n",
    "        node.left = self.fit(left_subset_X, left_subset_y)\n",
    "        node.right = self.fit(right_subset_X, right_subset_y)\n",
    "        self._tree.append(node)\n",
    "        self._current_depth -= 1\n",
    "        return node\n",
    "    def _tree_search(self, data_point, node):\n",
    "        \"\"\"\n",
    "        This method is a recursive solution to find the correct \n",
    "        leaf node for a test data_point.\n",
    "        \"\"\"\n",
    "        if node.feature_name == 'leaf':\n",
    "            return node.feature_value         \n",
    "        elif data_point[node.feature_name] > node.feature_value:\n",
    "            cls_dist = self._tree_search(data_point, node.right)\n",
    "        elif data_point[node.feature_name] <= node.feature_value:\n",
    "            cls_dist = self._tree_search(data_point, node.left)\n",
    "        return cls_dist\n",
    "\n",
    "    def predict_proba(self, data):\n",
    "        \"\"\"\n",
    "        Gets the class distribution in the leaf where the new data point\n",
    "        belongs and calculates mode of that\n",
    "        distribution to calculate the class,\n",
    "        and also returns probability.\n",
    "        \"\"\"\n",
    "        label = []\n",
    "        prob = []\n",
    "        for idx, point in data.iterrows():\n",
    "            cls_dist = self._tree_search(point, self._tree[-1])\n",
    "            predicted_class = cls_dist.mode()['z'][0]\n",
    "            label.append(predicted_class)\n",
    "            probability = len(\n",
    "                cls_dist[cls_dist['z'] == predicted_class])/len(cls_dist)\n",
    "            prob.append(probability)\n",
    "        return label, prob\n",
    "    def _best_node(self, X_subset, y_subset):\n",
    "        # calculate gini with received data\n",
    "        gini_before = self._calc_gini(y_subset)\n",
    "        print('gini before: ', gini_before)\n",
    "        # select a feature and corresponding value\n",
    "        features = X_subset.columns.values\n",
    "        deltas = defaultdict(list)\n",
    "        for feature in features:\n",
    "            uniques = X_subset[feature].unique()\n",
    "            for value in uniques:  \n",
    "                # calculate left and right subset\n",
    "                left_subset = y_subset.iloc[\n",
    "                    X_subset.index[X_subset[feature] <= value]]\n",
    "                right_subset = y_subset.iloc[\n",
    "                    X_subset.index[X_subset[feature] > value]]\n",
    "                # for each subset, calculate gini\n",
    "                left_gini = self._calc_gini(left_subset)\n",
    "                right_gini = self._calc_gini(right_subset)\n",
    "                gini_after = (len(\n",
    "                    left_subset)/len(X_subset))*left_gini\n",
    "                + (len(right_subset)/len(X_subset))*right_gini\n",
    "                # calculate delta, and make it default if max gain.\n",
    "                delta = gini_before - gini_after\n",
    "                # store the delta along with feature and value\n",
    "                deltas[feature].append({value:[delta, gini_after]})\n",
    "        # find the right feature-value combination which has maximum delta\n",
    "        max_gain = 0\n",
    "        node = None\n",
    "        for name, feature in deltas.items():\n",
    "            for value_delta_gini in feature:\n",
    "                value, delta_gini = next(iter(value_delta_gini.items()))\n",
    "                if delta_gini[0] > max_gain:\n",
    "                    node = Node(\n",
    "                        name=name, \n",
    "                        value=value, \n",
    "                        delta=delta_gini[0], \n",
    "                        gini_after=delta_gini[1])\n",
    "                    max_gain = delta_gini[0]\n",
    "        #print('best node: ', node)\n",
    "        return node\n",
    "            \n",
    "    def _calc_gini(self, y_subset):\n",
    "        target_name = y_subset.columns.values\n",
    "        classes = y_subset[target_name[0]].unique()\n",
    "        ratio_sum = 0\n",
    "        for label in classes:\n",
    "            num_instances = len(y_subset[y_subset[target_name[0]] == label])\n",
    "            ratio_sum += ((num_instances/len(y_subset)) ** 2)\n",
    "        gini = 1-ratio_sum\n",
    "        return gini\n",
    "                \n",
    "    def _subset(self, node, X_subset, y_subset):\n",
    "        \"\"\"\n",
    "        subsets the data into right and left subsets based on feature split.\n",
    "        \"\"\"\n",
    "        left_subset_X = X_subset[\n",
    "            X_subset[node.feature_name] <= node.feature_value]\n",
    "        left_subset_y = y_subset.iloc[\n",
    "            X_subset.index[X_subset[node.feature_name] <= node.feature_value]]\n",
    "        right_subset_X = X_subset[\n",
    "            X_subset[node.feature_name] > node.feature_value]\n",
    "        right_subset_y = y_subset.iloc[\n",
    "            X_subset.index[X_subset[node.feature_name] > node.feature_value]]\n",
    "        return left_subset_X, left_subset_y, right_subset_X, right_subset_y\n",
    "    @property\n",
    "    def tree_(self):\n",
    "        return self._tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('dummy.csv')\n",
    "X_train = data[['x1', 'x2', 'x3']]\n",
    "y_train = data[['z']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cur_depth:  0\n",
      "gini before:  0.6577777777777778\n",
      "feature_name:  x1 feature_split:  4.1 delta:  0.6577777777777778 gini:  0.0\n",
      "cur_depth:  1\n",
      "gini before:  0.0\n",
      "this is a pure leaf\n",
      "class distribution:     z\n",
      "0  1\n",
      "1  1\n",
      "2  1\n",
      "3  1\n",
      "4  1\n",
      "5  1\n",
      "cur_depth:  1\n",
      "gini before:  0.49382716049382713\n",
      "feature_name:  x1 feature_split:  4.5 delta:  0.49382716049382713 gini:  0.0\n",
      "cur_depth:  2\n",
      "gini before:  0.0\n",
      "this is a pure leaf\n",
      "class distribution:     z\n",
      "0  0\n",
      "cur_depth:  2\n",
      "gini before:  0.5\n",
      "feature_name:  x1 feature_split:  5.5 delta:  0.5 gini:  0.0\n",
      "class distribution:     z\n",
      "0  2\n",
      "class distribution:     z\n",
      "0  0\n",
      "1  2\n",
      "2  0\n",
      "3  2\n",
      "4  2\n",
      "5  0\n",
      "6  0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.Node at 0x7f62e89be908>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model =  DecisionTree(depth=2, score='gini')\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## results for tree above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Root node: N1: X1 = 4.1<br>\n",
    "Gini before split: 0.6577<br>\n",
    "Gini after split: 0.292929<br>\n",
    "Delta: 0.361<br>\n",
    "Left Child: Leaf with distribution [1,1,1,1,1,1]<br>\n",
    "Right Child: N2<br>\n",
    "\n",
    "Node N2: X1 = 6.9<br>\n",
    "Gini before split: 0.4938271<br>\n",
    "Gini after split: 0.292929<br>\n",
    "Delta: 0.1975<br>\n",
    "Left Child: N3<br>\n",
    "right Child: Leaf with distribution [0,0,0]<br>\n",
    "\n",
    "Node N3: X1 = 4.5<br>\n",
    "Gini before split: 0.44444<br>\n",
    "Gini after split: 0.2666<br>\n",
    "Delta: 0.1777<br>\n",
    "Left child: Leaf with distribution [0]<br>\n",
    "Right child: leaf with distribution [2,2,2,2,0]<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = []\n",
    "test_data.append([4.1, -0.1, 2.2])\n",
    "test_data.append([6.1, 0.4, 1.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.DataFrame(test_data, columns=['x1', 'x2', 'x3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POINT:  [4.1, -0.1, 2.2]  LABEL:  1  PROB:  1.0\n",
      "POINT:  [6.1, 0.4, 1.3]  LABEL:  0  PROB:  0.5714285714285714\n"
     ]
    }
   ],
   "source": [
    "label, probability = model.predict_proba(test)\n",
    "for idx, point in enumerate(test_data):\n",
    "    print('POINT: ', point, ' LABEL: ', label[idx], ' PROB: ', probability[idx])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
